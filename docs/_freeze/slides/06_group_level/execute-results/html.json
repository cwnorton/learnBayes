{
  "hash": "ed41468ea807086b4ed12a6018ab43c0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Introduction to Bayesian Linear Models\"\nsubtitle: \"05 - More on priors\"\nauthor: \"Stefano Coretta\"\ninstitute: \"University of Edinburgh\"\neditor: source\nformat:\n  mono-light-revealjs:\n    theme: [default, custom.scss]\n    history: false\nfilters:\n  - tachyonsextra\nexecute: \n  echo: true\n---\n\n\n\n::: {.cell}\n\n:::\n\n\n## Group-level effects\n\n::: box-note\n\n**Group-level effects** are the Bayesian equivalent of frequentist random effects.\n\nAs with the population-level effects, the interpretation of the group-level effects is the same as that of the frequentist random effects, but you have a full (posterior) probability distribution instead of a point estimate.\n\n:::\n\n## Group-level priors\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_prior(\n  RT ~ 0 + IsWord + IsWord:PhonLev_c + (0 + IsWord + IsWord:PhonLev_c | Subject),\n  family = lognormal,\n  data = mald\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                prior class                  coef   group resp dpar nlpar lb ub\n               (flat)     b                                                    \n               (flat)     b           IsWordFALSE                              \n               (flat)     b IsWordFALSE:PhonLev_c                              \n               (flat)     b            IsWordTRUE                              \n               (flat)     b  IsWordTRUE:PhonLev_c                              \n               lkj(1)   cor                                                    \n               lkj(1)   cor                       Subject                      \n student_t(3, 0, 2.5)    sd                                                0   \n student_t(3, 0, 2.5)    sd                       Subject                  0   \n student_t(3, 0, 2.5)    sd           IsWordFALSE Subject                  0   \n student_t(3, 0, 2.5)    sd IsWordFALSE:PhonLev_c Subject                  0   \n student_t(3, 0, 2.5)    sd            IsWordTRUE Subject                  0   \n student_t(3, 0, 2.5)    sd  IsWordTRUE:PhonLev_c Subject                  0   \n student_t(3, 0, 2.5) sigma                                                0   \n       source\n      default\n (vectorized)\n (vectorized)\n (vectorized)\n (vectorized)\n      default\n (vectorized)\n      default\n (vectorized)\n (vectorized)\n (vectorized)\n (vectorized)\n (vectorized)\n      default\n```\n\n\n:::\n:::\n\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrm_5_priors <- c(\n  prior(normal(7, 0.5), class = b, coef = IsWordFALSE),\n  prior(normal(7, 0.5), class = b, coef = IsWordTRUE),\n  prior(normal(0, 0.1), class = b, coef = `IsWordFALSE:PhonLev_c`),\n  prior(normal(0, 0.1), class = b, coef = `IsWordTRUE:PhonLev_c`),\n  prior(cauchy(0, 0.02), class = sigma),\n  prior(cauchy(0, 0.01), class = sd),\n  prior(lkj(2), class = cor)\n)\n```\n:::\n\n\n## Prior predictive checks\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrm_5_priorpp <- brm(\n  RT ~ 0 + IsWord + IsWord:PhonLev_c + (0 + IsWord + IsWord:PhonLev_c | Subject),\n  family = lognormal,\n  prior = brm_5_priors,\n  data = mald,\n  sample_prior = \"only\",\n  cores = 4,\n  file = \"data/cache/brm_5_priorpp\",\n  seed = my_seed\n)\n```\n:::\n\n\n## Prior predictive checks: plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconditional_effects(brm_5_priorpp, \"PhonLev_c:IsWord\")\n```\n\n::: {.cell-output-display}\n![](06_group_level_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n## Run the model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrm_5 <- brm(\n  RT ~ 0 + IsWord + IsWord:PhonLev_c + (0 + IsWord + IsWord:PhonLev_c | Subject),\n  family = lognormal,\n  prior = brm_5_priors,\n  data = mald,\n  cores = 4,\n  file = \"data/cache/brm_5\",\n  seed = my_seed\n)\n```\n:::\n\n\n## Model summary\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrm_5\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: lognormal \n  Links: mu = identity; sigma = identity \nFormula: RT ~ 0 + IsWord + IsWord:PhonLev_c + (0 + IsWord + IsWord:PhonLev_c | Subject) \n   Data: mald (Number of observations: 3000) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~Subject (Number of levels: 30) \n                                                Estimate Est.Error l-95% CI\nsd(IsWordTRUE)                                      0.07      0.01     0.05\nsd(IsWordFALSE)                                     0.11      0.02     0.08\nsd(IsWordTRUE:PhonLev_c)                            0.01      0.00     0.00\nsd(IsWordFALSE:PhonLev_c)                           0.01      0.01     0.00\ncor(IsWordTRUE,IsWordFALSE)                         0.56      0.14     0.25\ncor(IsWordTRUE,IsWordTRUE:PhonLev_c)               -0.04      0.37    -0.72\ncor(IsWordFALSE,IsWordTRUE:PhonLev_c)              -0.06      0.37    -0.73\ncor(IsWordTRUE,IsWordFALSE:PhonLev_c)              -0.12      0.34    -0.73\ncor(IsWordFALSE,IsWordFALSE:PhonLev_c)             -0.29      0.35    -0.83\ncor(IsWordTRUE:PhonLev_c,IsWordFALSE:PhonLev_c)     0.04      0.38    -0.68\n                                                u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(IsWordTRUE)                                      0.09 1.00     1672     2460\nsd(IsWordFALSE)                                     0.14 1.00     1453     2297\nsd(IsWordTRUE:PhonLev_c)                            0.02 1.00     2433     1442\nsd(IsWordFALSE:PhonLev_c)                           0.02 1.00     1595     1446\ncor(IsWordTRUE,IsWordFALSE)                         0.80 1.00     1199     1989\ncor(IsWordTRUE,IsWordTRUE:PhonLev_c)                0.69 1.00     4944     2715\ncor(IsWordFALSE,IsWordTRUE:PhonLev_c)               0.65 1.00     4708     3065\ncor(IsWordTRUE,IsWordFALSE:PhonLev_c)               0.59 1.00     4670     2622\ncor(IsWordFALSE,IsWordFALSE:PhonLev_c)              0.50 1.00     3757     2670\ncor(IsWordTRUE:PhonLev_c,IsWordFALSE:PhonLev_c)     0.73 1.00     3205     2757\n\nRegression Coefficients:\n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIsWordTRUE                6.85      0.01     6.82     6.88 1.00     1246\nIsWordFALSE               6.97      0.02     6.93     7.01 1.00     1552\nIsWordTRUE:PhonLev_c      0.03      0.01     0.02     0.04 1.00     5067\nIsWordFALSE:PhonLev_c     0.02      0.01     0.01     0.03 1.00     6071\n                      Tail_ESS\nIsWordTRUE                1997\nIsWordFALSE               2216\nIsWordTRUE:PhonLev_c      2707\nIsWordFALSE:PhonLev_c     2723\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.26      0.00     0.26     0.27 1.00     5289     3176\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\n## Conditional posterior probability distributions\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconditional_effects(brm_5, \"PhonLev_c:IsWord\")\n```\n\n::: {.cell-output-display}\n![](06_group_level_files/figure-revealjs/brm-5-cond-1.png){width=960}\n:::\n:::\n\n\n## Getting group-level adjustments\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrm_5_shrunk <- brm_5 |>\n  spread_draws(r_Subject[Subject,term]) |>\n  mean_qi() |>\n  mutate(source = \"shrunk\")\n\ngmean_RT <- mean(mald$RT_log, na.rm = TRUE)\n\noriginal <- mald |>\n  group_by(Subject) |>\n  summarise(\n    mean_RT = mean(RT_log) ,\n    sd_RT = sd(RT_log),\n    lower = mean_RT - 1.96 * sd_RT,\n    upper = mean_RT + 1.96 * sd_RT\n  )\n```\n:::\n\n\n## Plotting group-level adjustments for `IsWordTRUE`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrm_5_shrunk |>\n  filter(term %in% c(\"IsWordTRUE\")) |>\n  ggplot(aes(r_Subject, reorder(as.character(Subject), r_Subject))) +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  geom_point(size = 2) +\n  geom_errorbarh(aes(xmin = .lower, xmax = .upper)) +\n  geom_point(data = original, aes(mean_RT - gmean_RT, Subject), colour = \"red\", size = 2, alpha = 0.6) +\n  facet_grid(cols = vars(term)) +\n  labs(\n    title = \"By-subject conditional mode for Intercept\",\n    x = \"Conditional mode\",\n    y = \"Subject\",\n    caption = str_wrap(\"The red dots mark the by-subject mean RT from the raw data.\")\n  ) +\n  xlim(-.4, .4)\n```\n\n::: {.cell-output-display}\n![](06_group_level_files/figure-revealjs/brm-1-shrunk-iwtrue-1.png){width=960}\n:::\n:::\n\n\n## Plotting group-level adjustments for `IsWordTRUE`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrm_5_shrunk |>\n  filter(term %in% c(\"IsWordFALSE\")) |>\n  ggplot(aes(r_Subject, reorder(as.character(Subject), r_Subject))) +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  geom_point(size = 2) +\n  geom_errorbarh(aes(xmin = .lower, xmax = .upper)) +\n  geom_point(data = original, aes(mean_RT - gmean_RT, Subject), colour = \"red\", size = 2, alpha = 0.6) +\n  facet_grid(cols = vars(term)) +\n  labs(\n    title = \"By-subject conditional mode for Intercept\",\n    x = \"Conditional mode\",\n    y = \"Subject\",\n    caption = str_wrap(\"The red dots mark the by-subject mean RT from the raw data.\")\n  ) +\n  xlim(-.4, .4)\n```\n\n::: {.cell-output-display}\n![](06_group_level_files/figure-revealjs/brm-1-shrunk-iwfalse-1.png){width=960}\n:::\n:::\n",
    "supporting": [
      "06_group_level_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}